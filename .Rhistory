# Bayesian Inference
# Setting up loss matrix dependant on state and choice
loss.mat = matrix(c(0, 2, 6, 1.5, 2, 2.5, 3, 2, 1.5), nrow = 3, byrow=T)
colnames(loss.mat) = c("S(0)", "S(30)", "S(60)")
rownames(loss.mat) = c("Order 0", "Order 30", "Order 60")
loss.mat
prior.probs = c(0.3, 0.4, 0.3)
exp.loss = loss.mat %*% prior.probs
exp.loss
loss.PI = apply(loss.mat, 2, min) %*% prior.probs
loss.PI
EVPI = min(exp.loss) - loss.PI
EVPI
EVPI = min(exp.loss) - loss.PI
EVPI
cond.probs = matrix(c(0.1, 0.4, 0.85, 0.9, 0.6, 0.15))
colnames(cond.probs) = c("S1(0)", "S2(30)", "S3(60)")
rownames(cond.probs) = c("Serious", "Not Serious")
cond.probs
EVPI = min(exp.loss) - loss.PI
EVPI
cond.probs = matrix(c(0.1, 0.4, 0.85, 0.9, 0.6, 0.15), nrow = 2, byrow = T)
colnames(cond.probs) = c("S1(0)", "S2(30)", "S3(60)")
rownames(cond.probs) = c("Serious", "Not Serious")
cond.probs
joint.probs = t(apply(cond.probs, 1, function(x) x*prior.probs))
joint.probs
joint.probs = t(apply(cond.probs, 1, function(x) x*prior.probs))
joint.probs
pred.probs = rowSums(joint.probs)
posterior = joint.probs/pred.probs
posterior = joint.probs/pred.probs
posterior
posterior.exp.losses = cbind(loss.mat %*% posterior[1,], loss.mat %*% posterior[2,])
posterior.exp.losses
predictive.exp.loss = apply(posterior.exp.losses, 2, min) %*% pred.probs
predictive.exp.loss
EVSI = min(exp.loss) - predictive.exp.loss
EVSI
bayes.decision = function(payoff.mat, priors, cond.probs){
exp.loss = payoff.mat %*% priors
loss.PI = apply(payoff.mat, 2, min) %*% priors
EVPI = min(exp.loss) - loss.PI
joint.probs = t(apply(cond.probs, 1, function(x) x*priors))
pred.probs = rowSums(joint.probs)
posterior = joint.probs/pred.probs
posterior.exp.losses = cbind(payoff.mat %*% posterior [1,], payoff.mat %*%posterior [2,])
predictive.exp.loss = apply(posterior.exp.losses, 2, min) %*% pred.probs
EVSI = min(exp.loss) - predictive.exp.loss
return(list("EVPI" = EVPI, "Posterior Probs" = posterior, "Posterior exp." = posterior.exp.losses, "Predictive Exp" = predictive.exp.loss, "EVSI" = EVSI))
}
steel = bayes.decision(loss.mat, priors, cond.probs)
steel
steel = bayes.decision(loss.mat, prior.probs, cond.probs)
steel
library(tree)
package(tree)
library(visNetwork)
library(bnlearn)
library(visNetwork)
install.packages("bnlearn")
install.packages("visNetwork")
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
# The following initializes usage of Bioc devel
BiocManager::install(version='devel')
BiocManager::install("Rgraphviz")
# Bayesian Networks Tutorial SACAIR 2020
install.packages("BiocManager")
# The following initializes usage of Bioc devel
BiocManager::install(version='devel')
BiocManager::install("Rgraphviz")
boxplot (iris$Sepal.Length)
boxplot (iris$Sepal.Length ~ iris$Species, col="blue")
with (iris, boxplot (Sepal.Length ~ Species, col="green", notch=T))
## Mean and sd of BOD data set
BOD
mean(BOD$demand)
sd (BOD$demand)
## Frequencies and relative frequencies of rivers data set
my.breaks <- c(5,10,15,20,25,30,35,40)*100
freq.table <- table(cut(rivers,breaks=my.breaks))
names(freq.table) <- paste(paste("(",my.breaks[-8],sep=""), paste(my.breaks[-1],"]",sep=""),sep=",")
freq.table
relfreq.table <- freq.table/sum(freq.table)
relfreq.table
hist(rivers,col="red")
## relationship between two variables
with (swiss, plot (Education,Examination))
with (swiss, cor (Education,Examination))
cor(swiss)
## f-test and t-test for beaver data
### F-test for equality of variances
my.f.test <- function (x1,x2)
{
s1 <- sd(x1)
s2 <- sd(x2)
n1 <- length(x1)
n2 <- length(x2)
if (s1 > s2)
{  test.stat <- (s1/s2)^2
p.val <- 1 - pf(test.stat, n1-1, n2-1)
}
else
{ test.stat <- (s2/s1)^2
p.val <- 1 - pf(test.stat, n2-1, n1-1)
}
cat ("Testing the hypothesis: variance 1 (",s1^2,") = variance 2 (",s2^2,")\n")
print (paste("Test statistic",test.stat),sep="=")
cat ("with associated p-value ")
cat (p.val, "\n")
p.val
}
my.f.test(beaver1$temp,beaver2$temp)
### t-test for equality of variances
## Since variances are unequal, a t-test for differing variances is used
t.test (beaver1$temp, beaver2$temp, alternative="less", var.equal=FALSE)
boxplot (iris$Sepal.Length)
boxplot (iris$Sepal.Length ~ iris$Species, col="blue")
with (iris, boxplot (Sepal.Length ~ Species, col="green", notch=T))
install.packages("ca", "FactoMineR")
install.packages(c("ca", "FactoMineR")
install.packages(c("ca", "FactoMineR")
library(ca)
library(FactoMineR)
install.packages(c("ca", "FactoMineR")
install.packages(c("ca", "FactoMineR"))
install.packages(c("ca", "FactoMineR"))
library(ca)
library(FactoMineR)
install.packages(c("ca", "FactoMineR"))
library(ca)
library(FactoMineR)
rm(list=ls())
install.packages('ISLR')
library(ISLR)
library(help = 'ISLR')
library(tree)
data(Auto)
rm(list=ls())
install.packages('ISLR')
install.packages("ISLR")
library(ISLR)
library(help = 'ISLR')
library(tree)
data(Auto)
attach(Auto)
head(Auto)
set.seed(1)
train <- sample(1:nrow(Auto), 0.8*nrow(Auto))
tree1 <- tree(mpg ~ cylinders + displacement + horsepower + weight + acceleration + year + origin, data=Auto, subset=train)
tree1 <- tree(mpg ~ . - name, data=Auto, subset=train)
summary(tree1)
tree1 <- tree(mpg ~ . - name, data=Auto, subset=train, mindev=0.01, minsize=10, mincut=5)
summary(tree1)
tree1 <- tree(mpg ~ . - name, data=Auto)
summary(tree1)
set.seed(1)
set.seed(1)
train <- sample(1:nrow(Auto), 0.8*nrow(Auto))
tree1 <- tree(mpg ~ cylinders + displacement + horsepower + weight + acceleration + year + origin, data=Auto, subset=train)
tree1 <- tree(mpg ~ . - name, data=Auto, subset=train)
summary(tree1)
train.size
train.length
length(train)
set.seed(1)
nrow(Auto)
set.seed(1)
train <- sample(1:nrow(Auto), 0.8*nrow(Auto))
see
seed
library(mlbench)
RNGkind(sample.kind = 'default')
data(Vehicle)
head(Vehicle)
attach(Vehicle)
set.seed(1)
train <- sample(1:nrow(Vehicle), 0.7*nrow(Vehicle))
library(randomForest)
set.seed(1)
my_rf = randomForest(Class ~ ., data=Vehicle, subset=train, importance=F)
my_rf$mtry
summary(my_rf)
varImpPlot(my_rf, type=2)
my_rf_pred <- predict(my_rf, newdata = Vehicle[-train,])
ytest <- Vehicle[-train, 'Class']
table(my_rf_pred, ytest, dnn = c('predicted', 'true'))
(rf_err <- mean(my_rf_pred != ytest))
my_rf_pred <- predict(my_rf, newdata = Vehicle[-train,])
(bagged_err <- mean(bag_vehicles_pred != ytest))
bagged_err
set.seed(1)
bag_vehicles <- randomForest(Class ~ ., data = Vehicle, subset = train,
mtry = ncol(Vehicle) - 1, #for bagging, use all predictors
importance = F) #keep track of reduction in loss function
# and more (see ?randomForest)
summary(bag_vehicles)
bag_vehicles
bag_vehicles_pred = predict(bag_vehicles, newdata=Vehicle[-train,])
summary(bag_vehicles_pred)
summary(Vehicle[-train,]$Class)
(bagged_err <- mean(bag_vehicles_pred != ytest))
bagged_err
performTests = function(data_frame) {
print("Regular vs Indexing")
print(wilcox.test(data_frame$regular, data_frame$regular_with_indexing, paired=TRUE))
print("Regular vs Binary")
print(wilcox.test(data_frame$regular, data_frame$binary, paired=TRUE))
print("Regular vs Binary with Indexing")
print(wilcox.test(data_frame$regular, data_frame$binary_with_indexing, paired=TRUE))
}
performTests(hundred_rank_diff_ante)
hundred_rank_diff_ante = read.csv("outputranks100queries_DIFFANTE.csv")
hundred_rank_same_ante = read.csv("outputranks100queries_SAME_ANTE.csv")
hundred_rank_half_repeated_ante = read.csv("outputranks100queries_half_repeated_ante.csv")
hundred_rank_1st_rank = read.csv("outputranks100queries_1strank.csv")
hundred_rank_100th_rank = read.csv("outputranks100queries_100thrank.csv")
fifty_rank_diff_ante = read.csv("outputranks50queries_DIFFANTE.csv")
fifty_rank_same_ante = read.csv("outputranks50queries_SAME_ANTE.csv")
fifty_rank_half_repeated_ante = read.csv("outputranks50queries_half_repeated_ante.csv")
fifty_rank_1st_rank = read.csv("outputranks50queries_1strank.csv")
fifty_rank_50th_rank = read.csv("outputranks50queries_50thrank.csv")
ten_rank_diff_ante = read.csv("outputranks10queries_DIFFANTE.csv")
ten_rank_same_ante = read.csv("outputranks10queries_SAME_ANTE.csv")
ten_rank_half_repeated_ante = read.csv("outputranks10queries_half_repeated_ante.csv")
ten_rank_1st_rank = read.csv("outputranks10queries_1strank.csv")
ten_rank_10th_rank = read.csv("outputranks10queries_10thrank.csv")
setwd("~/UNIVERSITY/RATIONAL CLOSURE")
hundred_rank_diff_ante = read.csv("outputranks100queries_DIFFANTE.csv")
hundred_rank_same_ante = read.csv("outputranks100queries_SAME_ANTE.csv")
hundred_rank_half_repeated_ante = read.csv("outputranks100queries_half_repeated_ante.csv")
hundred_rank_1st_rank = read.csv("outputranks100queries_1strank.csv")
hundred_rank_100th_rank = read.csv("outputranks100queries_100thrank.csv")
fifty_rank_diff_ante = read.csv("outputranks50queries_DIFFANTE.csv")
fifty_rank_same_ante = read.csv("outputranks50queries_SAME_ANTE.csv")
fifty_rank_half_repeated_ante = read.csv("outputranks50queries_half_repeated_ante.csv")
fifty_rank_1st_rank = read.csv("outputranks50queries_1strank.csv")
fifty_rank_50th_rank = read.csv("outputranks50queries_50thrank.csv")
ten_rank_diff_ante = read.csv("outputranks10queries_DIFFANTE.csv")
ten_rank_same_ante = read.csv("outputranks10queries_SAME_ANTE.csv")
ten_rank_half_repeated_ante = read.csv("outputranks10queries_half_repeated_ante.csv")
ten_rank_1st_rank = read.csv("outputranks10queries_1strank.csv")
ten_rank_10th_rank = read.csv("outputranks10queries_10thrank.csv")
performTests(hundred_rank_diff_ante)
performTests(hundred_rank_same_ante)
performTests(hundred_rank_half_repeated_ante)
performTests(hundred_rank_1st_rank)
performTests(hundred_rank_100th_rank)
View(performTests)
performTests(fifty_rank_diff_ante)
(fifty_rank_same_ante)
performTests(fifty_rank_same_ante)
performTests(fifty_rank_half_repeated_ante)
performTests(fifty_rank_1st_rank)
performTests(fifty_rank_50th_rank)
performTests(ten_rank_diff_ante)
performTests(ten_rank_same_ante)
performTests(ten_rank_half_repeated_ante)
performTests(ten_rank_1st_rank)
performTests(ten_rank_10th_rank)
norm_50ranks_diff_ante = read.csv("outputdist_50queries_DIFFANTE1.csv")
norm_50ranks_same_ante = read.csv("outputdist_50queries_SAME_ANTE1.csv")
norm_50ranks_half_repeated_ante = read.csv("outputdist_50queries_half_repeated_ante1.csv")
norm_50ranks_1st_rank = read.csv("outputdist_50queries_1strank1.csv")
norm_50ranks_50th_rank = read.csv("outputdist_50queries_50thrank1.csv")
expo_50ranks_diff_ante = read.csv("outputdist_50queries_DIFFANTE2.csv")
expo_50ranks_same_ante = read.csv("outputdist_50queries_SAME_ANTE2.csv")
expo_50ranks_half_repeated_ante = read.csv("outputdist_50queries_half_repeated_ante2.csv")
expo_50ranks_1st_rank = read.csv("outputdist_50queries_1strank2.csv")
expo_50ranks_50th_rank = read.csv("outputdist_50queries_50thrank2.csv")
performTests(norm_50ranks_diff_ante)
performTests(norm_50ranks_same_ante)
performTests(norm_50ranks_half_repeated_ante)
performTests(norm_50ranks_1st_rank)
performTests(norm_50ranks_50th_rank)
performTests(expo_50ranks_diff_ante)
performTests(expo_50ranks_same_ante)
performTests(norm_50ranks_diff_ante)
performTests(norm_50ranks_same_ante)
performTests(norm_50ranks_half_repeated_ante)
performTests(norm_50ranks_1st_rank)
performTests(norm_50ranks_50th_rank)
performTests(expo_50ranks_diff_ante)
performTests(expo_50ranks_same_ante)
performTests(expo_50ranks_half_repeated_ante)
performTests(expo_50ranks_1st_rank)
performTests(expo_50ranks_50th_rank)
